#!/usr/bin/env python3
"""
Automated Roofline Model Analysis Tool

åŠŸèƒ½:
1. è‡ªåŠ¨è®¡ç®— Arithmetic Intensity (AI)
2. ç”Ÿæˆ Roofline å›¾è¡¨
3. åˆ¤æ–­ Memory-bound è¿˜æ˜¯ Compute-bound
4. æä¾›ä¼˜åŒ–å»ºè®®

ä½¿ç”¨:
    python roofline.py --flops=<flops> --bytes=<bytes> --time=<time_ms>
    python roofline.py --kernel=<binary>  # è‡ªåŠ¨ä» NCU æå–
    python roofline.py --help
"""

import argparse
import subprocess
import json
import sys
from typing import Dict, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import numpy as np


class GPUModel(Enum):
    """GPU å‹å·åŠå…¶ç¡¬ä»¶å‚æ•°"""
    A100 = {
        'name': 'NVIDIA A100',
        'peak_fp32_tflops': 19.5,
        'peak_fp16_tflops': 312,  # With Tensor Core
        'peak_bandwidth_gb_s': 1555,
        'ridge_point_fp32': 19.5 * 1000 / 1555,  # ~12.5 FLOPS/Byte
        'ridge_point_fp16': 312 * 1000 / 1555,   # ~200 FLOPS/Byte
    }
    V100 = {
        'name': 'NVIDIA V100',
        'peak_fp32_tflops': 15.7,
        'peak_fp16_tflops': 125,
        'peak_bandwidth_gb_s': 900,
        'ridge_point_fp32': 15.7 * 1000 / 900,
        'ridge_point_fp16': 125 * 1000 / 900,
    }
    RTX3090 = {
        'name': 'NVIDIA RTX 3090',
        'peak_fp32_tflops': 35.6,
        'peak_fp16_tflops': 71,
        'peak_bandwidth_gb_s': 936,
        'ridge_point_fp32': 35.6 * 1000 / 936,
        'ridge_point_fp16': 71 * 1000 / 936,
    }


@dataclass
class RooflineResult:
    """Roofline åˆ†æç»“æœ"""
    arithmetic_intensity: float  # FLOPS/Byte
    achieved_gflops: float
    achieved_bandwidth_gb_s: float
    gpu_model: str
    peak_compute_gflops: float
    peak_bandwidth_gb_s: float
    ridge_point: float
    bottleneck: str  # "Memory-bound" or "Compute-bound"
    ceiling: float  # ç†è®ºæ€§èƒ½ä¸Šç•Œ (GFLOPS)
    efficiency: float  # å®é™…æ€§èƒ½ / ç†è®ºä¸Šç•Œ
    optimization_suggestions: list

    def __str__(self):
        return f"""
{'=' * 70}
Roofline Model Analysis
{'=' * 70}

GPU: {self.gpu_model}
  Peak Compute: {self.peak_compute_gflops:.1f} GFLOPS
  Peak Bandwidth: {self.peak_bandwidth_gb_s:.1f} GB/s
  Ridge Point: {self.ridge_point:.2f} FLOPS/Byte

Kernel Performance:
  Arithmetic Intensity (AI): {self.arithmetic_intensity:.3f} FLOPS/Byte
  Achieved Performance: {self.achieved_gflops:.2f} GFLOPS
  Achieved Bandwidth: {self.achieved_bandwidth_gb_s:.2f} GB/s

Analysis:
  Bottleneck: {self.bottleneck}
  Performance Ceiling: {self.ceiling:.2f} GFLOPS
  Efficiency: {self.efficiency:.1f}%

Optimization Suggestions:
""" + '\n'.join(f"  â€¢ {s}" for s in self.optimization_suggestions)


class RooflineAnalyzer:
    """Roofline æ¨¡å‹åˆ†æå™¨"""

    def __init__(self, gpu_model: GPUModel = GPUModel.A100, precision: str = 'fp32'):
        """
        Args:
            gpu_model: GPU å‹å·
            precision: ç²¾åº¦ ('fp32' or 'fp16')
        """
        self.gpu = gpu_model.value
        self.precision = precision

        # é€‰æ‹©å¯¹åº”ç²¾åº¦çš„å³°å€¼æ€§èƒ½
        if precision == 'fp32':
            self.peak_compute = self.gpu['peak_fp32_tflops'] * 1000  # GFLOPS
            self.ridge_point = self.gpu['ridge_point_fp32']
        else:  # fp16
            self.peak_compute = self.gpu['peak_fp16_tflops'] * 1000
            self.ridge_point = self.gpu['ridge_point_fp16']

        self.peak_bandwidth = self.gpu['peak_bandwidth_gb_s']

    def analyze(
        self,
        flops: float,
        bytes_accessed: float,
        time_ms: float
    ) -> RooflineResult:
        """
        Roofline åˆ†æ

        Args:
            flops: æ€»æµ®ç‚¹æ“ä½œæ•°
            bytes_accessed: æ€»å†…å­˜è®¿é—®å­—èŠ‚æ•°
            time_ms: æ‰§è¡Œæ—¶é—´ (æ¯«ç§’)

        Returns:
            RooflineResult: åˆ†æç»“æœ
        """
        # è®¡ç®— Arithmetic Intensity
        ai = flops / bytes_accessed if bytes_accessed > 0 else 0

        # è®¡ç®—å®é™…æ€§èƒ½
        time_s = time_ms / 1000.0
        achieved_gflops = (flops / 1e9) / time_s if time_s > 0 else 0
        achieved_bandwidth = (bytes_accessed / 1e9) / time_s if time_s > 0 else 0

        # åˆ¤æ–­ç“¶é¢ˆ
        if ai < self.ridge_point:
            bottleneck = "Memory-bound"
            # ç†è®ºä¸Šç•Œ = AI Ã— Peak Bandwidth
            ceiling = ai * self.peak_bandwidth
        else:
            bottleneck = "Compute-bound"
            # ç†è®ºä¸Šç•Œ = Peak Compute
            ceiling = self.peak_compute

        # è®¡ç®—æ•ˆç‡
        efficiency = (achieved_gflops / ceiling * 100) if ceiling > 0 else 0

        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        suggestions = self._generate_suggestions(
            ai, bottleneck, efficiency, achieved_bandwidth
        )

        return RooflineResult(
            arithmetic_intensity=ai,
            achieved_gflops=achieved_gflops,
            achieved_bandwidth_gb_s=achieved_bandwidth,
            gpu_model=self.gpu['name'],
            peak_compute_gflops=self.peak_compute,
            peak_bandwidth_gb_s=self.peak_bandwidth,
            ridge_point=self.ridge_point,
            bottleneck=bottleneck,
            ceiling=ceiling,
            efficiency=efficiency,
            optimization_suggestions=suggestions
        )

    def _generate_suggestions(
        self,
        ai: float,
        bottleneck: str,
        efficiency: float,
        achieved_bw: float
    ) -> list:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []

        if bottleneck == "Memory-bound":
            suggestions.append(
                f"ğŸ”´ Kernel æ˜¯ Memory-bound (AI={ai:.3f} < Ridge Point={self.ridge_point:.2f})"
            )

            if efficiency < 50:
                suggestions.append(
                    "å†…å­˜è®¿é—®æ•ˆç‡ä½ï¼Œä¼˜åŒ–æ–¹å‘:"
                    "\n       1. æ£€æŸ¥ memory coalescing (NCU: sectors_per_request)"
                    "\n       2. ä½¿ç”¨ float4 å‘é‡åŒ–è®¿é—®"
                    "\n       3. è€ƒè™‘ Shared Memory (å¦‚æœæœ‰æ•°æ®é‡ç”¨)"
                )
            elif efficiency < 80:
                suggestions.append(
                    "å†…å­˜è®¿é—®å·²ä¼˜åŒ–ï¼Œä½†ä»å—å¸¦å®½é™åˆ¶:"
                    "\n       1. Kernel Fusion (å‡å°‘æ˜¾å­˜å¾€è¿”)"
                    "\n       2. å¢åŠ  Arithmetic Intensity (æ›´å¤šè®¡ç®—/æ•°æ®)"
                    "\n       3. è€ƒè™‘æ··åˆç²¾åº¦ (FP16 å‡å°‘å¸¦å®½éœ€æ±‚)"
                )
            else:
                suggestions.append(
                    f"âœ… å†…å­˜å¸¦å®½å·²æ¥è¿‘æé™ (æ•ˆç‡ {efficiency:.1f}%)"
                    "\n       â†’ æ— éœ€è¿›ä¸€æ­¥ä¼˜åŒ–å†…æ ¸"
                    "\n       â†’ è€ƒè™‘ç®—å­èåˆæˆ–ç³»ç»Ÿçº§ä¼˜åŒ–"
                )

            # ä¼°ç®—æå‡ç©ºé—´
            potential_speedup = self.peak_bandwidth / achieved_bw
            suggestions.append(
                f"ç†è®ºæå‡ç©ºé—´: {potential_speedup:.2f}x (å¦‚æœè¾¾åˆ° 100% å¸¦å®½)"
            )

        else:  # Compute-bound
            suggestions.append(
                f"ğŸ”µ Kernel æ˜¯ Compute-bound (AI={ai:.3f} > Ridge Point={self.ridge_point:.2f})"
            )

            if efficiency < 50:
                suggestions.append(
                    "è®¡ç®—æ•ˆç‡ä½ï¼Œä¼˜åŒ–æ–¹å‘:"
                    "\n       1. ä½¿ç”¨ Tensor Core (FP16/TF32 for GEMM)"
                    "\n       2. å¢åŠ  ILP (æŒ‡ä»¤çº§å¹¶è¡Œ)"
                    "\n       3. Loop Unrolling"
                    "\n       4. æ£€æŸ¥ warp divergence"
                )
            elif efficiency < 80:
                suggestions.append(
                    "è®¡ç®—å·²ä¼˜åŒ–ï¼Œè¿›ä¸€æ­¥æå‡:"
                    "\n       1. Tensor Core (å¦‚æœæ˜¯çŸ©é˜µä¹˜æ³•)"
                    "\n       2. æ··åˆç²¾åº¦ (FP16 æ€§èƒ½ ~16x FP32)"
                    "\n       3. ç®—å­èåˆ"
                )
            else:
                suggestions.append(
                    f"âœ… è®¡ç®—æ•ˆç‡å·²æ¥è¿‘æé™ (æ•ˆç‡ {efficiency:.1f}%)"
                    "\n       â†’ è€ƒè™‘ Tensor Core æˆ–æ··åˆç²¾åº¦"
                )

        # é€šç”¨å»ºè®®
        if ai < 0.5:
            suggestions.append(
                f"âš ï¸  AI éå¸¸ä½ ({ai:.3f}), è€ƒè™‘:"
                "\n       â€¢ ç®—å­èåˆ (å‡å°‘å†…å­˜è®¿é—®)"
                "\n       â€¢ å¢åŠ è®¡ç®—é‡ (å¦‚æœä¸šåŠ¡å…è®¸)"
            )

        return suggestions

    def plot_roofline(
        self,
        results: list,
        output_file: str = 'roofline.png',
        show_points: bool = True
    ):
        """
        ç»˜åˆ¶ Roofline å›¾

        Args:
            results: RooflineResult åˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶å
            show_points: æ˜¯å¦æ˜¾ç¤ºå®é™…æ€§èƒ½ç‚¹
        """
        fig, ax = plt.subplots(figsize=(12, 8))

        # AI èŒƒå›´
        ai_range = np.logspace(-2, 3, 1000)  # 0.01 to 1000 FLOPS/Byte

        # Memory-bound åŒºåŸŸ (æ–œçº¿): Performance = AI Ã— Peak BW
        memory_bound = ai_range * self.peak_bandwidth
        memory_bound = np.minimum(memory_bound, self.peak_compute)

        # Compute-bound åŒºåŸŸ (å¹³çº¿): Performance = Peak Compute
        compute_bound = np.ones_like(ai_range) * self.peak_compute

        # Roofline (å–æœ€å°å€¼)
        roofline = np.minimum(memory_bound, compute_bound)

        # ç»˜åˆ¶ Roofline
        ax.loglog(ai_range, roofline, 'k-', linewidth=3, label='Roofline')

        # å¡«å……åŒºåŸŸ
        ax.fill_between(ai_range, roofline, alpha=0.2, color='gray')

        # Ridge Point æ ‡è®°
        ax.axvline(x=self.ridge_point, color='red', linestyle='--',
                  linewidth=2, alpha=0.7,
                  label=f'Ridge Point ({self.ridge_point:.1f} FLOPS/Byte)')

        # ç»˜åˆ¶å®é™…æ€§èƒ½ç‚¹
        if show_points and results:
            colors = ['#e74c3c', '#3498db', '#27ae60', '#f39c12', '#9b59b6']

            for i, result in enumerate(results):
                color = colors[i % len(colors)]
                label = getattr(result, 'label', f'Kernel {i+1}')

                ax.scatter(result.arithmetic_intensity,
                          result.achieved_gflops,
                          s=200, color=color, marker='o',
                          edgecolors='black', linewidth=2,
                          label=label, zorder=5)

                # æ·»åŠ æ ‡ç­¾
                ax.annotate(
                    f'{label}\n({result.efficiency:.0f}%)',
                    xy=(result.arithmetic_intensity, result.achieved_gflops),
                    xytext=(10, 10), textcoords='offset points',
                    fontsize=9, fontweight='bold',
                    bbox=dict(boxstyle='round,pad=0.5', facecolor=color, alpha=0.3),
                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0')
                )

        # è®¾ç½®åæ ‡è½´
        ax.set_xlabel('Arithmetic Intensity (FLOPS/Byte)',
                     fontsize=14, fontweight='bold')
        ax.set_ylabel('Performance (GFLOPS)',
                     fontsize=14, fontweight='bold')
        ax.set_title(f'Roofline Model - {self.gpu["name"]} ({self.precision.upper()})',
                    fontsize=16, fontweight='bold')

        ax.set_xlim([0.01, 1000])
        ax.set_ylim([1, self.peak_compute * 2])

        ax.grid(True, which='both', alpha=0.3)
        ax.legend(loc='lower right', fontsize=10)

        # æ·»åŠ åŒºåŸŸæ ‡æ³¨
        ax.text(0.02, self.peak_bandwidth * 0.02,
               'Memory-Bound\nRegion',
               fontsize=12, style='italic', alpha=0.7,
               bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))

        ax.text(self.ridge_point * 10, self.peak_compute * 0.8,
               'Compute-Bound\nRegion',
               fontsize=12, style='italic', alpha=0.7,
               bbox=dict(boxstyle='round', facecolor='cyan', alpha=0.3))

        plt.tight_layout()
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
        print(f"âœ“ Roofline chart saved to: {output_file}")

        return fig


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Roofline Model Analysis Tool",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Manual input
  python roofline.py --flops=1e9 --bytes=256e6 --time=1.5

  # From NCU profile
  python roofline.py --kernel=./vector_add

  # Multiple kernels comparison
  python roofline.py --kernels v0_naive v1_coalesced v4_optimized --plot

  # Specify GPU model
  python roofline.py --flops=1e9 --bytes=256e6 --time=1.5 --gpu=V100 --precision=fp16
        """
    )

    parser.add_argument('--flops', type=float, help='Total floating point operations')
    parser.add_argument('--bytes', type=float, help='Total bytes accessed')
    parser.add_argument('--time', type=float, help='Execution time in ms')

    parser.add_argument('--kernel', help='Kernel binary (auto-extract from NCU)')
    parser.add_argument('--kernels', nargs='+', help='Multiple kernels for comparison')

    parser.add_argument('--gpu', choices=['A100', 'V100', 'RTX3090'],
                       default='A100', help='GPU model')
    parser.add_argument('--precision', choices=['fp32', 'fp16'],
                       default='fp32', help='Precision')

    parser.add_argument('--plot', action='store_true', help='Generate Roofline plot')
    parser.add_argument('--output', default='roofline.png', help='Output plot file')

    args = parser.parse_args()

    # é€‰æ‹© GPU å‹å·
    gpu_enum = getattr(GPUModel, args.gpu)
    analyzer = RooflineAnalyzer(gpu_enum, args.precision)

    results = []

    # æ¨¡å¼ 1: æ‰‹åŠ¨è¾“å…¥
    if args.flops and args.bytes and args.time:
        result = analyzer.analyze(args.flops, args.bytes, args.time)
        result.label = 'User Kernel'
        results.append(result)
        print(result)

    # æ¨¡å¼ 2: å•ä¸ª kernel (TODO: ä» NCU æå–)
    elif args.kernel:
        print("âš ï¸  Auto-extraction from NCU not yet implemented")
        print("   Please use --flops, --bytes, --time for now")
        sys.exit(1)

    # æ¨¡å¼ 3: å¤šä¸ª kernels å¯¹æ¯” (TODO)
    elif args.kernels:
        print("âš ï¸  Multi-kernel comparison not yet implemented")
        print("   Please use --flops, --bytes, --time for now")
        sys.exit(1)

    else:
        parser.print_help()
        sys.exit(1)

    # ç»˜å›¾
    if args.plot and results:
        analyzer.plot_roofline(results, args.output)


if __name__ == "__main__":
    main()
