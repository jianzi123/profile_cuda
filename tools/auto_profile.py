#!/usr/bin/env python3
"""
Automated NCU Profiling Tool

åŠŸèƒ½:
1. è‡ªåŠ¨è¿è¡Œ NCU å¹¶æ”¶é›†å…³é”®æŒ‡æ ‡
2. è§£æ NCU è¾“å‡ºå¹¶æå–æ€§èƒ½æ•°æ®
3. è‡ªåŠ¨è¯Šæ–­ç“¶é¢ˆ (Memory-bound/Compute-bound)
4. ç”Ÿæˆä¼˜åŒ–å»ºè®®

ä½¿ç”¨:
    python auto_profile.py <binary> [args]
    python auto_profile.py ./v0_naive
    python auto_profile.py ./gemm_v2 1024 1024 1024
"""

import subprocess
import json
import re
import sys
import os
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from enum import Enum


class Bottleneck(Enum):
    """ç“¶é¢ˆç±»å‹"""
    MEMORY_BOUND = "Memory-bound"
    COMPUTE_BOUND = "Compute-bound"
    LAUNCH_BOUND = "Launch-bound"
    BALANCED = "Balanced"
    UNKNOWN = "Unknown"


@dataclass
class ProfileResult:
    """NCU åˆ†æç»“æœ"""
    binary: str
    kernel_name: str
    duration_ms: float
    sm_throughput: float  # Percentage
    memory_throughput: float  # Percentage
    sectors_per_request: float
    l2_hit_rate: float  # Percentage
    achieved_occupancy: float  # Percentage
    dram_bandwidth_gb_s: float
    bottleneck: Bottleneck
    optimization_suggestions: List[str]

    def __str__(self):
        return f"""
{'=' * 70}
NCU Profile Result
{'=' * 70}

Binary: {self.binary}
Kernel: {self.kernel_name}

Performance:
  Duration: {self.duration_ms:.4f} ms
  DRAM Bandwidth: {self.dram_bandwidth_gb_s:.2f} GB/s

Speed of Light:
  SM Throughput: {self.sm_throughput:.1f}% {'ğŸ”´' if self.sm_throughput < 40 else 'ğŸŸ¡' if self.sm_throughput < 60 else 'ğŸŸ¢'}
  Memory Throughput: {self.memory_throughput:.1f}% {'ğŸ”´' if self.memory_throughput < 40 else 'ğŸŸ¡' if self.memory_throughput < 60 else 'ğŸŸ¢'}

Memory Analysis:
  Sectors per Request: {self.sectors_per_request:.2f} {'âœ…' if self.sectors_per_request < 1.5 else 'ğŸ”´'}
  L2 Hit Rate: {self.l2_hit_rate:.1f}%

Occupancy:
  Achieved: {self.achieved_occupancy:.1f}%

Bottleneck: {self.bottleneck.value}

Optimization Suggestions:
""" + '\n'.join(f"  â€¢ {s}" for s in self.optimization_suggestions)


class NCUProfiler:
    """NCU è‡ªåŠ¨åŒ–åˆ†æå™¨"""

    # å…³é”®æŒ‡æ ‡åˆ—è¡¨
    KEY_METRICS = [
        "gpu__time_duration.avg",
        "sm__throughput.avg.pct_of_peak_sustained_elapsed",
        "gpu__compute_memory.avg.pct_of_peak_sustained_elapsed",
        "l1tex__average_t_sectors_per_request",
        "lts__t_sector_hit_rate.pct",
        "sm__warps_active.avg.pct_of_peak_sustained_active",
        "dram__bytes.sum",
        "smsp__sass_thread_inst_executed_op_fadd.sum",
        "smsp__sass_thread_inst_executed_op_fmul.sum",
        "smsp__sass_inst_executed_op_global_ld.sum",
        "smsp__average_warps_issue_stalled_long_scoreboard",
        "smsp__average_warps_issue_stalled_barrier",
    ]

    def __init__(self, ncu_path: str = "ncu"):
        """
        Args:
            ncu_path: NCU å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„
        """
        self.ncu_path = ncu_path
        self._check_ncu_available()

    def _check_ncu_available(self):
        """æ£€æŸ¥ NCU æ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(
                [self.ncu_path, "--version"],
                capture_output=True,
                text=True,
                check=True
            )
            print(f"âœ“ NCU version: {result.stdout.strip()}")
        except FileNotFoundError:
            print(f"âœ— Error: NCU not found at '{self.ncu_path}'")
            print("  Please install NVIDIA Nsight Compute or specify path")
            sys.exit(1)
        except subprocess.CalledProcessError as e:
            print(f"âœ— Error running NCU: {e}")
            sys.exit(1)

    def profile(self, binary: str, args: List[str] = None) -> ProfileResult:
        """
        è¿è¡Œ NCU å¹¶åˆ†æç»“æœ

        Args:
            binary: è¦åˆ†æçš„äºŒè¿›åˆ¶æ–‡ä»¶
            args: ä¼ é€’ç»™äºŒè¿›åˆ¶æ–‡ä»¶çš„å‚æ•°

        Returns:
            ProfileResult: åˆ†æç»“æœ
        """
        if not os.path.exists(binary):
            raise FileNotFoundError(f"Binary not found: {binary}")

        print(f"\n{'=' * 70}")
        print(f"Profiling: {binary}")
        if args:
            print(f"Arguments: {' '.join(args)}")
        print(f"{'=' * 70}\n")

        # æ„å»º NCU å‘½ä»¤
        cmd = [
            self.ncu_path,
            "--metrics", ",".join(self.KEY_METRICS),
            "--csv",
            binary
        ]
        if args:
            cmd.extend(args)

        print(f"Running: {' '.join(cmd)}\n")

        # è¿è¡Œ NCU
        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=False  # Don't raise on non-zero exit (NCU may return non-zero even on success)
            )

            # NCU è¾“å‡ºåœ¨ stdout ä¸­
            output = result.stdout

            # è§£æç»“æœ
            profile_result = self._parse_ncu_output(output, binary)

            return profile_result

        except subprocess.CalledProcessError as e:
            print(f"âœ— Error running NCU:")
            print(f"  stdout: {e.stdout}")
            print(f"  stderr: {e.stderr}")
            raise

    def _parse_ncu_output(self, output: str, binary: str) -> ProfileResult:
        """è§£æ NCU CSV è¾“å‡º"""

        # åˆ†ç¦» CSV éƒ¨åˆ†
        lines = output.strip().split('\n')

        # æ‰¾åˆ° CSV å¤´
        csv_start = None
        for i, line in enumerate(lines):
            if '"ID"' in line or 'Metric Name' in line:
                csv_start = i
                break

        if csv_start is None:
            # å°è¯•æ‰¾åˆ°åŒ…å«æŒ‡æ ‡çš„è¡Œ
            for i, line in enumerate(lines):
                if 'gpu__time_duration' in line:
                    csv_start = i - 1  # Header åº”è¯¥åœ¨å‰ä¸€è¡Œ
                    break

        if csv_start is None:
            print("âœ— Error: Could not parse NCU output")
            print("\nRaw output:")
            print(output)
            raise ValueError("Failed to parse NCU CSV output")

        # è§£æ CSV
        csv_data = lines[csv_start:]

        # æå–æŒ‡æ ‡å€¼
        metrics = {}

        for line in csv_data:
            # CSV æ ¼å¼: "ID","Kernel Name","Metric Name","Metric Unit","Metric Value"
            parts = line.split(',')

            if len(parts) < 5:
                continue

            # ç§»é™¤å¼•å·
            parts = [p.strip('"') for p in parts]

            if parts[2] in self.KEY_METRICS or any(m in parts[2] for m in self.KEY_METRICS):
                metric_name = parts[2]
                metric_value = parts[4] if len(parts) > 4 else parts[3]

                # å°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                try:
                    # å¤„ç†ç™¾åˆ†å·
                    if '%' in metric_value:
                        metric_value = metric_value.replace('%', '')
                    # å¤„ç†é€—å·åˆ†éš”çš„å¤§æ•°å­—
                    metric_value = metric_value.replace(',', '')
                    metrics[metric_name] = float(metric_value)
                except ValueError:
                    # ä¿ç•™å­—ç¬¦ä¸²
                    metrics[metric_name] = metric_value

        # æå– kernel åç§°
        kernel_name = "unknown"
        for line in csv_data:
            parts = line.split(',')
            if len(parts) >= 2:
                parts = [p.strip('"') for p in parts]
                if parts[1] and parts[1] != "Kernel Name":
                    kernel_name = parts[1]
                    break

        # è®¡ç®—æ´¾ç”ŸæŒ‡æ ‡
        duration_ms = metrics.get("gpu__time_duration.avg", 0) / 1e6  # ns to ms
        sm_throughput = metrics.get("sm__throughput.avg.pct_of_peak_sustained_elapsed", 0)
        memory_throughput = metrics.get("gpu__compute_memory.avg.pct_of_peak_sustained_elapsed", 0)
        sectors_per_request = metrics.get("l1tex__average_t_sectors_per_request", 0)
        l2_hit_rate = metrics.get("lts__t_sector_hit_rate.pct", 0)
        occupancy = metrics.get("sm__warps_active.avg.pct_of_peak_sustained_active", 0)

        # è®¡ç®— DRAM å¸¦å®½
        dram_bytes = metrics.get("dram__bytes.sum", 0)
        dram_bandwidth_gb_s = (dram_bytes / 1e9) / (duration_ms / 1000.0) if duration_ms > 0 else 0

        # è¯Šæ–­ç“¶é¢ˆ
        bottleneck = self._diagnose_bottleneck(
            sm_throughput,
            memory_throughput,
            sectors_per_request,
            occupancy
        )

        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        suggestions = self._generate_suggestions(
            bottleneck,
            sectors_per_request,
            l2_hit_rate,
            occupancy,
            metrics
        )

        return ProfileResult(
            binary=binary,
            kernel_name=kernel_name,
            duration_ms=duration_ms,
            sm_throughput=sm_throughput,
            memory_throughput=memory_throughput,
            sectors_per_request=sectors_per_request,
            l2_hit_rate=l2_hit_rate,
            achieved_occupancy=occupancy,
            dram_bandwidth_gb_s=dram_bandwidth_gb_s,
            bottleneck=bottleneck,
            optimization_suggestions=suggestions
        )

    def _diagnose_bottleneck(
        self,
        sm_throughput: float,
        memory_throughput: float,
        sectors_per_request: float,
        occupancy: float
    ) -> Bottleneck:
        """
        å››è±¡é™è¯Šæ–­ç“¶é¢ˆ

        å‚è€ƒ NCU UI Guide ä¸­çš„ Speed of Light åˆ†æ
        """
        if memory_throughput > 60 and sm_throughput < 40:
            return Bottleneck.MEMORY_BOUND
        elif sm_throughput > 60 and memory_throughput < 40:
            return Bottleneck.COMPUTE_BOUND
        elif memory_throughput < 40 and sm_throughput < 40:
            if occupancy < 50:
                return Bottleneck.LAUNCH_BOUND
            else:
                return Bottleneck.UNKNOWN
        elif memory_throughput > 60 and sm_throughput > 60:
            return Bottleneck.BALANCED
        else:
            return Bottleneck.UNKNOWN

    def _generate_suggestions(
        self,
        bottleneck: Bottleneck,
        sectors_per_request: float,
        l2_hit_rate: float,
        occupancy: float,
        metrics: Dict[str, float]
    ) -> List[str]:
        """æ ¹æ®è¯Šæ–­ç»“æœç”Ÿæˆä¼˜åŒ–å»ºè®®"""

        suggestions = []

        # Memory coalescing
        if sectors_per_request > 1.5:
            suggestions.append(
                f"âŒ éåˆå¹¶è®¿é—® (sectors_per_request={sectors_per_request:.2f})"
                "\n     â†’ ä¿®å¤ä¸ºè¿ç»­è®¿é—® (é¢„æœŸ 8-10x æå‡)"
                "\n     â†’ å‚è€ƒ: benchmarks/vector_ops/vector_add/v0â†’v1"
            )

        # Bottleneck specific
        if bottleneck == Bottleneck.MEMORY_BOUND:
            suggestions.append(
                "ğŸ”´ Memory-bound ç“¶é¢ˆ"
                "\n     ä¼˜åŒ–æ–¹å‘:"
                "\n       1. Memory coalescing (å¦‚æœ sectors_per_request > 1.5)"
                "\n       2. Vectorization (float4)"
                "\n       3. Shared Memory (å¦‚æœæœ‰æ•°æ®é‡ç”¨)"
                "\n       4. Kernel Fusion (å‡å°‘æ˜¾å­˜å¾€è¿”)"
            )

            if sectors_per_request < 1.5:
                suggestions.append(
                    "âœ“ è®¿é—®å·²åˆå¹¶ï¼Œè€ƒè™‘:"
                    "\n     â†’ Vectorization (float4) - 1.5-2x æå‡"
                    "\n     â†’ Kernel Fusion - 2-5x æå‡"
                )

        elif bottleneck == Bottleneck.COMPUTE_BOUND:
            suggestions.append(
                "ğŸ”´ Compute-bound ç“¶é¢ˆ"
                "\n     ä¼˜åŒ–æ–¹å‘:"
                "\n       1. Tensor Core (FP16/TF32 for GEMM)"
                "\n       2. ILP (å¤šä¸ªç´¯åŠ å™¨)"
                "\n       3. Loop Unrolling"
                "\n       4. ç®—å­èåˆ (å‡å°‘ kernel launch)"
            )

        elif bottleneck == Bottleneck.LAUNCH_BOUND:
            suggestions.append(
                f"ğŸ”´ Launch-bound ç“¶é¢ˆ (Occupancy={occupancy:.1f}%)"
                "\n     ä¼˜åŒ–æ–¹å‘:"
                "\n       1. å¢åŠ  blocks/threads"
                "\n       2. å‡å°‘å¯„å­˜å™¨ä½¿ç”¨ (--maxrregcount)"
                "\n       3. å‡å°‘ Shared Memory ä½¿ç”¨"
                "\n       4. æ£€æŸ¥ warp divergence"
            )

        elif bottleneck == Bottleneck.BALANCED:
            suggestions.append(
                "âœ… æ€§èƒ½å·²ä¼˜åŒ– (SM å’Œ Memory éƒ½é«˜åˆ©ç”¨ç‡)"
                "\n     è¿›ä¸€æ­¥ä¼˜åŒ–æ–¹å‘:"
                "\n       1. ç³»ç»Ÿçº§ä¼˜åŒ– (kernel fusion, pipeline)"
                "\n       2. å¤š GPU å¹¶è¡Œ"
                "\n       3. æ··åˆç²¾åº¦ (FP16)"
            )

        # L2 cache
        if l2_hit_rate < 30 and bottleneck == Bottleneck.MEMORY_BOUND:
            suggestions.append(
                f"ğŸŸ¡ L2 Cache å‘½ä¸­ç‡ä½ ({l2_hit_rate:.1f}%)"
                "\n     â†’ æ­£å¸¸å¯¹äº streaming workload"
                "\n     â†’ å¦‚æœæœ‰å±€éƒ¨æ€§ï¼Œè€ƒè™‘ tiling/blocking"
            )

        # Occupancy
        if occupancy < 50:
            suggestions.append(
                f"ğŸŸ¡ Occupancy ä½ ({occupancy:.1f}%)"
                "\n     å¯èƒ½åŸå› :"
                "\n       â€¢ å¯„å­˜å™¨ä½¿ç”¨è¿‡å¤š"
                "\n       â€¢ Shared Memory ä½¿ç”¨è¿‡å¤š"
                "\n       â€¢ Block size å¤ªå¤§/å¤ªå°"
                "\n     â†’ ä½¿ç”¨ --resource-usage æŸ¥çœ‹é™åˆ¶å› ç´ "
            )

        # Barrier stalls
        barrier_stall = metrics.get("smsp__average_warps_issue_stalled_barrier", 0)
        if barrier_stall > 20:
            suggestions.append(
                f"ğŸŸ¡ Barrier Stall é«˜ ({barrier_stall:.1f}%)"
                "\n     â†’ __syncthreads() è¿‡å¤šæˆ– warp divergence"
                "\n     â†’ æ£€æŸ¥æ˜¯å¦è¯¯ç”¨ Shared Memory (å‚è€ƒ v3_shared_tiling åä¾‹)"
            )

        if not suggestions:
            suggestions.append("âœ… æœªå‘ç°æ˜æ˜¾ç“¶é¢ˆï¼Œæ€§èƒ½è‰¯å¥½")

        return suggestions


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("Usage: python auto_profile.py <binary> [args...]")
        print("\nExamples:")
        print("  python auto_profile.py ./v0_naive")
        print("  python auto_profile.py ./gemm 1024 1024 1024")
        sys.exit(1)

    binary = sys.argv[1]
    args = sys.argv[2:] if len(sys.argv) > 2 else None

    profiler = NCUProfiler()
    result = profiler.profile(binary, args)

    print(result)

    # ä¿å­˜ç»“æœåˆ° JSON
    output_file = f"{os.path.basename(binary)}_profile.json"
    with open(output_file, 'w') as f:
        json.dump({
            'binary': result.binary,
            'kernel_name': result.kernel_name,
            'duration_ms': result.duration_ms,
            'sm_throughput': result.sm_throughput,
            'memory_throughput': result.memory_throughput,
            'sectors_per_request': result.sectors_per_request,
            'l2_hit_rate': result.l2_hit_rate,
            'achieved_occupancy': result.achieved_occupancy,
            'dram_bandwidth_gb_s': result.dram_bandwidth_gb_s,
            'bottleneck': result.bottleneck.value,
            'optimization_suggestions': result.optimization_suggestions
        }, f, indent=2)

    print(f"\nâœ“ Results saved to: {output_file}")


if __name__ == "__main__":
    main()
