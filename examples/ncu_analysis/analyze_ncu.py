#!/usr/bin/env python3
"""
NCU æŠ¥å‘Šè‡ªåŠ¨åˆ†æè„šæœ¬

ä½¿ç”¨æ–¹æ³•ï¼š
1. è¿è¡Œ NCU å¹¶å¯¼å‡º CSVï¼š
   ncu --csv --page raw ./program > ncu_output.csv

2. è¿è¡Œæ­¤è„šæœ¬åˆ†æï¼š
   python analyze_ncu.py ncu_output.csv
"""

import sys
import csv
import re
from typing import Dict, List, Tuple
from dataclasses import dataclass
from enum import Enum


class BottleneckType(Enum):
    COMPUTE_BOUND = "Compute-bound"
    MEMORY_BOUND = "Memory-bound"
    BALANCED = "Balanced"
    UNDER_UTILIZED = "Under-utilized"


@dataclass
class Metric:
    name: str
    value: float
    unit: str


class NCUAnalyzer:
    def __init__(self, csv_file: str):
        self.csv_file = csv_file
        self.metrics: Dict[str, Metric] = {}
        self.kernel_name = ""
        self.duration_ns = 0

    def parse_csv(self):
        """è§£æ NCU CSV è¾“å‡º"""
        with open(self.csv_file, 'r') as f:
            reader = csv.DictReader(f)
            for row in reader:
                metric_name = row.get('Metric Name', '')
                metric_value = row.get('Metric Value', '')
                metric_unit = row.get('Metric Unit', '')

                # è½¬æ¢ä¸ºæ•°å€¼
                try:
                    value = float(metric_value.replace(',', ''))
                except (ValueError, AttributeError):
                    value = 0.0

                self.metrics[metric_name] = Metric(metric_name, value, metric_unit)

                # æå– kernel åç§°
                if 'Kernel Name' in row:
                    self.kernel_name = row['Kernel Name']

    def get_metric(self, name: str, default: float = 0.0) -> float:
        """è·å–æŒ‡æ ‡å€¼"""
        return self.metrics.get(name, Metric(name, default, "")).value

    def analyze_bottleneck(self) -> BottleneckType:
        """ç¬¬ä¸€æ­¥ï¼šåˆ¤æ–­ç“¶é¢ˆç±»å‹"""
        sm_throughput = self.get_metric('sm__throughput.avg.pct_of_peak_sustained_elapsed')
        mem_throughput = self.get_metric('gpu__compute_memory_throughput.avg.pct_of_peak_sustained_elapsed')

        print("=" * 80)
        print("ç¬¬ä¸€æ­¥ï¼šSpeed of Light åˆ†æ")
        print("=" * 80)
        print(f"SM Throughput:          {sm_throughput:6.2f}%")
        print(f"Memory Throughput:      {mem_throughput:6.2f}%")
        print()

        # åˆ¤æ–­ç“¶é¢ˆç±»å‹
        if sm_throughput > 80 and mem_throughput < 60:
            bottleneck = BottleneckType.COMPUTE_BOUND
            print(f"ç»“è®º: {bottleneck.value} âœ“")
            print("è®¡ç®—å•å…ƒé«˜åº¦åˆ©ç”¨ï¼Œå†…å­˜ä¸æ˜¯ç“¶é¢ˆ")
        elif sm_throughput < 60 and mem_throughput > 80:
            bottleneck = BottleneckType.MEMORY_BOUND
            print(f"ç»“è®º: {bottleneck.value} âœ“")
            print("å†…å­˜å¸¦å®½æ¥è¿‘é¥±å’Œï¼Œè®¡ç®—å•å…ƒç©ºé—²")
        elif sm_throughput > 70 and mem_throughput > 70:
            bottleneck = BottleneckType.BALANCED
            print(f"ç»“è®º: {bottleneck.value} âœ“")
            print("è®¡ç®—å’Œå†…å­˜éƒ½æ¥è¿‘æé™ï¼Œä¼˜åŒ–å›°éš¾")
        else:
            bottleneck = BottleneckType.UNDER_UTILIZED
            print(f"ç»“è®º: {bottleneck.value} âš ")
            print("è®¡ç®—å’Œå†…å­˜éƒ½æœªå……åˆ†åˆ©ç”¨ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†æ")

        print()
        return bottleneck

    def analyze_memory(self):
        """ç¬¬äºŒæ­¥ï¼šMemory-bound æ·±å…¥åˆ†æ"""
        print("=" * 80)
        print("ç¬¬äºŒæ­¥ï¼šMemory æ·±å…¥åˆ†æ")
        print("=" * 80)

        # DRAM å¸¦å®½
        dram_throughput_pct = self.get_metric('dram__throughput.avg.pct_of_peak_sustained_elapsed')
        dram_bytes_read = self.get_metric('dram__bytes_read.sum')
        dram_bytes_write = self.get_metric('dram__bytes_write.sum')
        duration_ns = self.get_metric('gpu__time_duration.sum')

        if duration_ns > 0:
            total_bytes = dram_bytes_read + dram_bytes_write
            duration_sec = duration_ns / 1e9
            actual_bw_gbps = total_bytes / duration_sec / 1e9

            # å‡è®¾ A100ï¼Œç†è®ºå¸¦å®½ 1555 GB/s
            theoretical_bw = 1555
            bw_util = (actual_bw_gbps / theoretical_bw) * 100

            print(f"\nğŸ“Š DRAM å¸¦å®½åˆ†æ:")
            print(f"  DRAM Throughput:      {dram_throughput_pct:6.2f}%")
            print(f"  è¯»å–å­—èŠ‚æ•°:           {dram_bytes_read / 1e9:8.2f} GB")
            print(f"  å†™å…¥å­—èŠ‚æ•°:           {dram_bytes_write / 1e9:8.2f} GB")
            print(f"  å®é™…å¸¦å®½:             {actual_bw_gbps:8.2f} GB/s")
            print(f"  ç†è®ºå¸¦å®½:             {theoretical_bw:8.2f} GB/s (A100)")
            print(f"  å¸¦å®½åˆ©ç”¨ç‡:           {bw_util:6.2f}%")

            if bw_util < 80:
                print(f"  âš ï¸  å¸¦å®½åˆ©ç”¨ç‡ä½äº 80%ï¼Œæœ‰ä¼˜åŒ–ç©ºé—´")
            else:
                print(f"  âœ“ å¸¦å®½åˆ©ç”¨ç‡é«˜ï¼Œæ¥è¿‘ç¡¬ä»¶æé™")

        # L2 Cache
        l2_hit_rate = self.get_metric('lts__t_sector_hit_rate.pct')
        print(f"\nğŸ“Š L2 Cache åˆ†æ:")
        print(f"  L2 å‘½ä¸­ç‡:            {l2_hit_rate:6.2f}%")

        if l2_hit_rate > 70:
            print(f"  âœ“ L2 å‘½ä¸­ç‡è‰¯å¥½ï¼Œæ•°æ®æœ‰å¤ç”¨")
        elif l2_hit_rate > 50:
            print(f"  âš ï¸  L2 å‘½ä¸­ç‡ä¸€èˆ¬ï¼Œæœ‰æ”¹è¿›ç©ºé—´")
        else:
            print(f"  âŒ L2 å‘½ä¸­ç‡ä½ï¼Œæ•°æ®å‡ ä¹æ²¡æœ‰å¤ç”¨")
            print(f"     å»ºè®®ï¼šç®—å­èåˆã€Tilingã€å¢åŠ æ•°æ®å¤ç”¨")

        # L1 Cache
        l1_hit_rate = self.get_metric('l1tex__t_sector_hit_rate.pct')
        print(f"\nğŸ“Š L1/TEX Cache åˆ†æ:")
        print(f"  L1 å‘½ä¸­ç‡:            {l1_hit_rate:6.2f}%")

        if l1_hit_rate > 90:
            print(f"  âœ“ L1 å‘½ä¸­ç‡ä¼˜ç§€")
        elif l1_hit_rate > 70:
            print(f"  âš ï¸  L1 å‘½ä¸­ç‡ä¸€èˆ¬")
        else:
            print(f"  âŒ L1 å‘½ä¸­ç‡ä½")
            print(f"     å»ºè®®ï¼šä½¿ç”¨ Shared Memoryã€æé«˜æ•°æ®å±€éƒ¨æ€§")

        # Coalesced Access
        coalesced_ld = self.get_metric(
            'l1tex__average_t_sectors_per_request_pipe_lsu_mem_global_op_ld.ratio'
        )
        coalesced_st = self.get_metric(
            'l1tex__average_t_sectors_per_request_pipe_lsu_mem_global_op_st.ratio'
        )

        print(f"\nğŸ“Š Coalesced Access åˆ†æ:")
        print(f"  åŠ è½½ Coalesced ç¨‹åº¦:  {coalesced_ld:6.2f} (ç†æƒ³å€¼ = 1.0)")
        print(f"  å­˜å‚¨ Coalesced ç¨‹åº¦:  {coalesced_st:6.2f} (ç†æƒ³å€¼ = 1.0)")

        if coalesced_ld <= 1.2 and coalesced_st <= 1.2:
            print(f"  âœ“ å†…å­˜è®¿é—®æ¨¡å¼è‰¯å¥½ï¼Œæ¥è¿‘å®Œç¾åˆå¹¶")
        elif coalesced_ld <= 2.0 or coalesced_st <= 2.0:
            waste = ((max(coalesced_ld, coalesced_st) - 1.0) / max(coalesced_ld, coalesced_st)) * 100
            print(f"  âš ï¸  æœ‰éåˆå¹¶è®¿é—®ï¼Œæµªè´¹çº¦ {waste:.1f}% å¸¦å®½")
            print(f"     å»ºè®®ï¼šè°ƒæ•´è®¿é—®æ¨¡å¼ã€ä½¿ç”¨å‘é‡åŒ– (float4)")
        else:
            waste = ((max(coalesced_ld, coalesced_st) - 1.0) / max(coalesced_ld, coalesced_st)) * 100
            print(f"  âŒ ä¸¥é‡çš„éåˆå¹¶è®¿é—®ï¼Œæµªè´¹çº¦ {waste:.1f}% å¸¦å®½")
            print(f"     å»ºè®®ï¼šé‡æ–°è®¾è®¡å†…å­˜è®¿é—®æ¨¡å¼ã€ä½¿ç”¨ Shared Memory")

        # Bank Conflicts
        bank_conflicts = self.get_metric('l1tex__data_bank_conflicts_pipe_lsu.sum')
        shared_accesses = self.get_metric('l1tex__data_pipe_lsu_wavefronts_mem_shared.sum')

        if shared_accesses > 0:
            conflict_rate = (bank_conflicts / shared_accesses) * 100
            print(f"\nğŸ“Š Shared Memory Bank Conflicts:")
            print(f"  Bank Conflicts:       {bank_conflicts:10.0f}")
            print(f"  Shared Accesses:      {shared_accesses:10.0f}")
            print(f"  Conflict ç‡:          {conflict_rate:6.2f}%")

            if conflict_rate < 1:
                print(f"  âœ“ å‡ ä¹æ—  bank conflicts")
            elif conflict_rate < 10:
                print(f"  âš ï¸  æœ‰å°‘é‡ bank conflicts")
                print(f"     å»ºè®®ï¼šè€ƒè™‘æ·»åŠ  padding åˆ° shared memory æ•°ç»„")
            else:
                print(f"  âŒ ä¸¥é‡çš„ bank conflicts")
                print(f"     å»ºè®®ï¼šé‡æ–°ç»„ç»‡ shared memory è®¿é—®æ¨¡å¼ã€æ·»åŠ  padding")

        print()

    def analyze_compute(self):
        """ç¬¬äºŒæ­¥ï¼šCompute-bound æ·±å…¥åˆ†æ"""
        print("=" * 80)
        print("ç¬¬äºŒæ­¥ï¼šCompute æ·±å…¥åˆ†æ")
        print("=" * 80)

        # Warp Divergence
        threads_per_inst = self.get_metric('smsp__thread_inst_executed_per_inst_executed.ratio')
        print(f"\nğŸ“Š Warp Divergence åˆ†æ:")
        print(f"  å¹³å‡æ¯æŒ‡ä»¤æ‰§è¡Œçº¿ç¨‹æ•°: {threads_per_inst:6.2f} (ç†æƒ³å€¼ = 32)")

        if threads_per_inst >= 30:
            print(f"  âœ“ å‡ ä¹æ—  warp divergence")
        elif threads_per_inst >= 24:
            waste = ((32 - threads_per_inst) / 32) * 100
            print(f"  âš ï¸  æœ‰è½»å¾® divergenceï¼Œæµªè´¹çº¦ {waste:.1f}% è®¡ç®—")
            print(f"     å»ºè®®ï¼šæ£€æŸ¥åˆ†æ”¯ä»£ç ï¼Œå°½é‡è®© warp å†…çº¿ç¨‹æ‰§è¡Œç›¸åŒè·¯å¾„")
        else:
            waste = ((32 - threads_per_inst) / 32) * 100
            print(f"  âŒ ä¸¥é‡çš„ warp divergenceï¼Œæµªè´¹çº¦ {waste:.1f}% è®¡ç®—")
            print(f"     å»ºè®®ï¼šé‡ç»„æ•°æ®ã€å‡å°‘æ¡ä»¶åˆ†æ”¯ã€ä½¿ç”¨ warp åŸè¯­")

        # ILP
        issue_active = self.get_metric('smsp__issue_active.avg.pct_of_peak_sustained_active')
        print(f"\nğŸ“Š ILP (æŒ‡ä»¤çº§å¹¶è¡Œ) åˆ†æ:")
        print(f"  æŒ‡ä»¤å‘å°„æ´»è·ƒåº¦:       {issue_active:6.2f}%")

        if issue_active > 70:
            print(f"  âœ“ ILP åˆ©ç”¨ç‡è‰¯å¥½")
        elif issue_active > 50:
            print(f"  âš ï¸  ILP æœ‰æ”¹è¿›ç©ºé—´")
            print(f"     å»ºè®®ï¼šæ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªæ•°æ®ã€å¾ªç¯å±•å¼€")
        else:
            print(f"  âŒ ILP åˆ©ç”¨ç‡ä½")
            print(f"     å»ºè®®ï¼šå‘é‡åŒ–ã€æ‰‹åŠ¨å±•å¼€å¾ªç¯ã€å¢åŠ ç‹¬ç«‹æ“ä½œ")

        # FLOPs ç»Ÿè®¡
        fadd = self.get_metric('smsp__sass_thread_inst_executed_op_fadd_pred_on.sum')
        fmul = self.get_metric('smsp__sass_thread_inst_executed_op_fmul_pred_on.sum')
        ffma = self.get_metric('smsp__sass_thread_inst_executed_op_ffma_pred_on.sum')
        duration_ns = self.get_metric('gpu__time_duration.sum')

        if duration_ns > 0 and (fadd + fmul + ffma) > 0:
            fp32_flops = fadd + fmul + 2 * ffma
            duration_sec = duration_ns / 1e9
            tflops = fp32_flops / duration_sec / 1e12

            # A100 ç†è®ºå³°å€¼ï¼š19.5 TFLOPS
            peak_tflops = 19.5
            efficiency = (tflops / peak_tflops) * 100

            print(f"\nğŸ“Š FP32 æ€§èƒ½åˆ†æ:")
            print(f"  FP32 FLOPs:           {fp32_flops / 1e9:10.2f} GFLOPs")
            print(f"  å®é™…ååé‡:           {tflops:10.3f} TFLOPS")
            print(f"  ç†è®ºå³°å€¼:             {peak_tflops:10.3f} TFLOPS (A100)")
            print(f"  è®¡ç®—æ•ˆç‡:             {efficiency:6.2f}%")

        # Tensor Core æ£€æŸ¥
        tensor_active = self.get_metric('smsp__inst_executed_pipe_tensor.avg.pct_of_peak_sustained_active')
        if tensor_active > 0:
            print(f"\nğŸ“Š Tensor Core åˆ†æ:")
            print(f"  Tensor Core åˆ©ç”¨ç‡:   {tensor_active:6.2f}%")
            print(f"  âœ“ æ­£åœ¨ä½¿ç”¨ Tensor Cores")
        else:
            # æ£€æŸ¥æ˜¯å¦æœ‰ FP16 æ“ä½œ
            hadd = self.get_metric('smsp__sass_thread_inst_executed_op_hadd_pred_on.sum')
            hmul = self.get_metric('smsp__sass_thread_inst_executed_op_hmul_pred_on.sum')
            hfma = self.get_metric('smsp__sass_thread_inst_executed_op_hfma_pred_on.sum')

            if (hadd + hmul + hfma) > fp32_flops * 0.5:
                print(f"\nğŸ“Š Tensor Core æœºä¼š:")
                print(f"  âš ï¸  æ£€æµ‹åˆ°å¤§é‡ FP16 è®¡ç®—ï¼Œä½†æœªä½¿ç”¨ Tensor Cores")
                print(f"     å»ºè®®ï¼šè€ƒè™‘ä½¿ç”¨ WMMA API æˆ– cuBLAS")

        print()

    def analyze_occupancy(self):
        """ç¬¬äºŒæ­¥ï¼šOccupancy åˆ†æ"""
        print("=" * 80)
        print("ç¬¬äºŒæ­¥ï¼šOccupancy åˆ†æ")
        print("=" * 80)

        achieved_occ = self.get_metric('sm__warps_active.avg.pct_of_peak_sustained_active')

        print(f"\nğŸ“Š å ç”¨ç‡åˆ†æ:")
        print(f"  å®é™…å ç”¨ç‡:           {achieved_occ:6.2f}%")

        if achieved_occ > 60:
            print(f"  âœ“ å ç”¨ç‡è‰¯å¥½")
        elif achieved_occ > 40:
            print(f"  âš ï¸  å ç”¨ç‡ä¸­ç­‰ï¼Œæœ‰æå‡ç©ºé—´")
        else:
            print(f"  âŒ å ç”¨ç‡ä½ï¼Œä¸¥é‡é™åˆ¶æ€§èƒ½")
            print(f"     å»ºè®®ï¼šæ£€æŸ¥èµ„æºä½¿ç”¨ã€è°ƒæ•´ block size")

        print()

    def analyze_warp_state(self):
        """Warp åœé¡¿åˆ†æ"""
        print("=" * 80)
        print("Warp State åˆ†æ")
        print("=" * 80)

        stall_barrier = self.get_metric('smsp__warps_issue_stalled_barrier.avg.pct_of_peak_sustained_active')
        stall_long = self.get_metric('smsp__warps_issue_stalled_long_scoreboard.avg.pct_of_peak_sustained_active')
        stall_short = self.get_metric('smsp__warps_issue_stalled_short_scoreboard.avg.pct_of_peak_sustained_active')
        stall_not_selected = self.get_metric('smsp__warps_issue_stalled_not_selected.avg.pct_of_peak_sustained_active')

        print(f"\nğŸ“Š Warp åœé¡¿åˆ†å¸ƒ:")
        print(f"  Barrier (__syncthreads):  {stall_barrier:6.2f}%")
        print(f"  Long Scoreboard (Memory): {stall_long:6.2f}%")
        print(f"  Short Scoreboard (Compute):{stall_short:6.2f}%")
        print(f"  Not Selected (Occupancy): {stall_not_selected:6.2f}%")

        # æ‰¾å‡ºä¸»è¦åœé¡¿åŸå› 
        stalls = {
            'Barrier': stall_barrier,
            'Memory Latency': stall_long,
            'Compute Dependency': stall_short,
            'Low Occupancy': stall_not_selected,
        }

        max_stall_name = max(stalls, key=stalls.get)
        max_stall_value = stalls[max_stall_name]

        print(f"\n  ä¸»è¦åœé¡¿åŸå› : {max_stall_name} ({max_stall_value:.2f}%)")

        if max_stall_name == 'Barrier' and max_stall_value > 30:
            print(f"  å»ºè®®ï¼šå‡å°‘ __syncthreads() è°ƒç”¨é¢‘ç‡")
        elif max_stall_name == 'Memory Latency' and max_stall_value > 50:
            print(f"  å»ºè®®ï¼šä¼˜åŒ–å†…å­˜è®¿é—®ã€æé«˜ç¼“å­˜å‘½ä¸­ç‡")
        elif max_stall_name == 'Compute Dependency' and max_stall_value > 30:
            print(f"  å»ºè®®ï¼šæé«˜ ILPã€å‡å°‘æ•°æ®ä¾èµ–")
        elif max_stall_name == 'Low Occupancy' and max_stall_value > 40:
            print(f"  å»ºè®®ï¼šå¢åŠ  block æ•°é‡ã€ä¼˜åŒ–èµ„æºä½¿ç”¨")

        print()

    def generate_optimization_suggestions(self, bottleneck: BottleneckType):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        print("=" * 80)
        print("ğŸ’¡ ä¼˜åŒ–å»ºè®®æ€»ç»“")
        print("=" * 80)

        if bottleneck == BottleneckType.MEMORY_BOUND:
            print("\nâœ… ä¼˜å…ˆçº§ 1ï¼ˆæœ€é‡è¦ï¼‰ï¼š")
            print("  1. ç®—å­èåˆï¼šå°†å¤šä¸ª kernel åˆå¹¶ï¼Œå‡å°‘å†…å­˜è®¿é—®")
            print("  2. ä½¿ç”¨ Shared Memoryï¼šç¼“å­˜é¢‘ç¹è®¿é—®çš„æ•°æ®")

            print("\nâœ… ä¼˜å…ˆçº§ 2ï¼š")
            print("  3. å‘é‡åŒ–è®¿é—®ï¼šä½¿ç”¨ float4 æé«˜å¸¦å®½åˆ©ç”¨ç‡")
            print("  4. ä¼˜åŒ–è®¿é—®æ¨¡å¼ï¼šç¡®ä¿ coalesced access")

            print("\nâœ… ä¼˜å…ˆçº§ 3ï¼š")
            print("  5. æé«˜ç¼“å­˜å‘½ä¸­ç‡ï¼šTilingã€å¢åŠ æ•°æ®å¤ç”¨")
            print("  6. æ¶ˆé™¤ Bank Conflictsï¼šæ·»åŠ  padding")

        elif bottleneck == BottleneckType.COMPUTE_BOUND:
            print("\nâœ… ä¼˜å…ˆçº§ 1ï¼ˆæœ€é‡è¦ï¼‰ï¼š")
            print("  1. ä½¿ç”¨ Tensor Coresï¼šå¦‚æœæ˜¯çŸ©é˜µè¿ç®—")
            print("  2. å‡å°‘ Warp Divergenceï¼šé‡ç»„æ•°æ®ã€å‡å°‘åˆ†æ”¯")

            print("\nâœ… ä¼˜å…ˆçº§ 2ï¼š")
            print("  3. æé«˜ ILPï¼šæ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªæ•°æ®")
            print("  4. ä½¿ç”¨å¿«é€Ÿæ•°å­¦å‡½æ•°ï¼š__expf, __logf ç­‰")

            print("\nâœ… ä¼˜å…ˆçº§ 3ï¼š")
            print("  5. å¾ªç¯å±•å¼€ï¼š#pragma unroll")
            print("  6. ç®—æ³•ä¼˜åŒ–ï¼šå‡å°‘ä¸å¿…è¦çš„è®¡ç®—")

        elif bottleneck == BottleneckType.UNDER_UTILIZED:
            print("\nâœ… ä¼˜å…ˆçº§ 1ï¼ˆæœ€é‡è¦ï¼‰ï¼š")
            print("  1. æé«˜ Occupancyï¼šè°ƒæ•´ block sizeã€å‡å°‘èµ„æºä½¿ç”¨")
            print("  2. æ£€æŸ¥ Launch Configurationï¼šç¡®ä¿æœ‰è¶³å¤Ÿçš„ blocks")

            print("\nâœ… ä¼˜å…ˆçº§ 2ï¼š")
            print("  3. åˆ†æ Warp Stateï¼šæ‰¾å‡ºä¸»è¦åœé¡¿åŸå› ")
            print("  4. å‡å°‘åŒæ­¥å¼€é”€ï¼šå‡å°‘ __syncthreads()")

        print()

    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print(f"\n{'=' * 80}")
        print(f"NCU æ€§èƒ½åˆ†ææŠ¥å‘Š")
        print(f"{'=' * 80}")
        if self.kernel_name:
            print(f"Kernel: {self.kernel_name}")
        print()

        # è§£æ CSV
        self.parse_csv()

        # ç¬¬ä¸€æ­¥ï¼šåˆ¤æ–­ç“¶é¢ˆ
        bottleneck = self.analyze_bottleneck()

        # ç¬¬äºŒæ­¥ï¼šæ·±å…¥åˆ†æ
        if bottleneck == BottleneckType.MEMORY_BOUND:
            self.analyze_memory()
        elif bottleneck == BottleneckType.COMPUTE_BOUND:
            self.analyze_compute()
        elif bottleneck == BottleneckType.UNDER_UTILIZED:
            self.analyze_occupancy()
            self.analyze_warp_state()
        else:  # BALANCED
            print("Kernel æ€§èƒ½å·²æ¥è¿‘ç¡¬ä»¶æé™ï¼Œä¼˜åŒ–ç©ºé—´æœ‰é™")
            print("å¯ä»¥è€ƒè™‘ä»ç®—æ³•å±‚é¢ä¼˜åŒ–")
            print()

        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        self.generate_optimization_suggestions(bottleneck)


def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•ï¼š")
        print("  1. è¿è¡Œ NCU å¹¶å¯¼å‡º CSVï¼š")
        print("     ncu --csv --page raw ./program > ncu_output.csv")
        print("")
        print("  2. åˆ†æ CSVï¼š")
        print("     python analyze_ncu.py ncu_output.csv")
        sys.exit(1)

    csv_file = sys.argv[1]

    analyzer = NCUAnalyzer(csv_file)
    analyzer.run_analysis()


if __name__ == "__main__":
    main()
